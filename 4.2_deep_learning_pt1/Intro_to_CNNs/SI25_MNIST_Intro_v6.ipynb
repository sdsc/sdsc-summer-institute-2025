{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST exercise (handwritten printed digits recognition tutorial) ##\n",
    "**Goal: Introduction convolution feature maps, and features**\n",
    "\n",
    "**Exercise:**\n",
    "    \n",
    "Run the notebook, observe the images of filter weights and activations (at end)\n",
    "\n",
    "Try changing the filter size for the first convolution layer to something large (like 9x9 or 16x16)\n",
    "        How does that change the images of filter weights and activations?\n",
    "<br>\n",
    "Question to consider: for 10 digits what is min number of filters needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------- IMPORT STATEMENTS ---------------\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#---------------------------------------------\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "#Parameters for training\n",
    "# -----------------------------------\n",
    "num_worker2use = 4     #for parallel reading/prefetching of data (for bigger data)\n",
    "batch_size     = 256  \n",
    "max_numtrain   = 1024       #for this exercise, train on limited num of input, to save time\n",
    "max_numtest    = batch_size # and test on limited num of input\n",
    "epochs         = 10\n",
    "lrate          = 0.01\n",
    "numfilt        = 16   #Try 8 or 24? or a mininumal number like 2?\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# NOTE 3x3 kernel leaves 12x12 after maxpooling, so use 12 for reduced_size\n",
    "#     16x16 leaves 6x6\n",
    "#     9x9 leaves  9x9\n",
    "# --------------------------------------------------------------\n",
    "kernel_size2use= 3   #Try 9 or even 16,\n",
    "reduced_size   = 12    # also, see the note below in fwd method for 'MyNet' class\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "data_path      = './data'\n",
    "torch.manual_seed(777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "#   Define network class object and its \n",
    "#             initialization and forward function\n",
    "#             (other functions are inherited from torch.nn)\n",
    "# -------------------------------------------------------------\n",
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        #Conv:  input size 1 channel, output is number of filters, the \n",
    "        #  actual batch of input is implicit\n",
    "        # see:   https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "        self.conv1   = torch.nn.Conv2d(in_channels=1,out_channels=numfilt,kernel_size=kernel_size2use,stride=1) \n",
    "        self.linear1 = torch.nn.Linear(numfilt*reduced_size*reduced_size,16) #after max pooling it wil lbe 12 x12\n",
    "        self.linear2 = torch.nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        #Uncomment this to see what the size actually is after max pooling\n",
    "        #print('MYINFO  fwd, after conv1relu, x shape:',x.shape)\n",
    "\n",
    "        x = F.max_pool2d(x, 3, 2)\n",
    "        # <<<<<<<<<<<<<<<<<--------------------\n",
    "        #Uncomment this to see what the size actually is after max pooling\n",
    "        #print('MYINFO  fwd, after max, x shape:',x.shape)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        #not sure i need this   x = F.relu(x)\n",
    "        output = F.log_softmax(x, dim=1)  #log softmax for classfcnt or binary?\n",
    "        return output\n",
    "print('Net class defined ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "#   Define training function\n",
    "# --------------------------------------------------------\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    ''' This is called for each epoch.  \n",
    "        Arguments:  the model, the device to run on, data loader, optimizer, and current epoch\n",
    "    ''' \n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "      if batch_idx*batch_size>= max_numtrain:\n",
    "           break\n",
    "      else:\n",
    "        if batch_idx==0:  #print one message\n",
    "          print('INFO train, ep:',epoch,' batidx:',batch_idx, ' batch size:',target.shape[0])\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()                 #reset optimizer state\n",
    "        output = model(data)                  #get predictions\n",
    "        loss = F.nll_loss(output, target)     #get loss (nll_loss for softmax outputs)\n",
    "        loss.backward()                       #backprop loss\n",
    "        optimizer.step()                      #update weights\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "#   Define test function\n",
    "# -------------------------------------------------------------\n",
    "def test(model, device, test_loader):\n",
    "    ''' This is called for after training each epoch \n",
    "        Arguments:  the model, the device to run on, test data loader\n",
    "    ''' \n",
    "    model.eval()\n",
    "\n",
    "    #accumulate loss, accuracy info\n",
    "    total_loss    = 0\n",
    "    total_correct = 0\n",
    "    total         = 0\n",
    "    with torch.no_grad():\n",
    "      for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if batch_idx*batch_size>= max_numtest:\n",
    "           break\n",
    "        else:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output       = model(data)\n",
    "            total_loss  += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "\n",
    "            _, predicted  = torch.max(output, dim=1)\n",
    "            total_correct += (predicted == target).sum().item()\n",
    "            total         += output.shape[0]\n",
    "           \n",
    "    acc       = total_correct/total\n",
    "    test_loss = total_loss/total \n",
    "    print('INFO evaluation acc:',f'{acc:.4}',' loss:',f'{test_loss:.4}','tot:',total)\n",
    "    return acc,test_loss\n",
    "def get_activation(name, activation):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "    \n",
    "print('Train,test, support functions defined ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "#  Get device  \n",
    "#  (note, this is set up for 1 GPU device\n",
    "#    if this were to run on a full GPU node with >1 gpu device, you would\n",
    "#     want to get rank, world size info and set device id \n",
    "#     as in:   torch.cuda.set_device(local_rank) \n",
    "#     and then also run distributed initialization )\n",
    "# -------------------------------------------------\n",
    "use_cuda = torch.cuda.is_available() \n",
    "if use_cuda:\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print('INFO,  cuda, num gpu:',num_gpu)\n",
    "        device     = torch.cuda.current_device()\n",
    "        print('environ visdevs:',os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "else:\n",
    "        num_gpu = 0\n",
    "        print('INFO, cuda not available')\n",
    "        device  = torch.device(\"cpu\")   \n",
    "print('INFO, device is:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "#prepare images for network as they are loaded\n",
    "#   crop or other functions can be added here\n",
    "# -------------------------------------------\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  #])  #also transforms image pixels to 0,1 range from 0,255\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "dataset1 = datasets.MNIST(data_path, train=True, download=True,transform=transform)\n",
    "dataset2 = datasets.MNIST(data_path, train=False,download=True,transform=transform)\n",
    "\n",
    "train_loader =torch.utils.data.DataLoader(dataset1, \n",
    "            batch_size =batch_size,     sampler   =None,\n",
    "            num_workers=num_worker2use, pin_memory=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, \n",
    "            batch_size =batch_size,     sampler   =None,\n",
    "            num_workers=num_worker2use, pin_memory=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "#  Set up model\n",
    "# -------------------------------------------\n",
    "mymodel = MyNet().to(device)\n",
    "\n",
    "#summary(mymodel,input_size=(1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "#  Do training loop\n",
    "# -------------------------------------------\n",
    "\n",
    "# Dictionary to store activations\n",
    "activations = {}\n",
    "# Register hooks\n",
    "mymodel.conv1.register_forward_hook(get_activation('conv1', activations))\n",
    "\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr=lrate)\n",
    "\n",
    "train_results = []\n",
    "test_results  = []\n",
    "for epoch in range(epochs):\n",
    "        print('INFO about to train epoch:',epoch)\n",
    "        start_time=time.time()\n",
    "        train(mymodel, device, train_loader, optimizer, epoch)\n",
    "        print('INFO training time:',str.format('{0:.5f}', time.time()-start_time))\n",
    "        print('INFO train metrics for epoch:',epoch)\n",
    "        train_results.append(test(mymodel, device, train_loader))\n",
    "        print('INFO test metrices for epoch:',epoch)\n",
    "        test_results.append(test(mymodel, device, test_loader))\n",
    "\n",
    "print('INFO  done');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Below is code to plot and see results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape results\n",
    "train_results=np.array(train_results)\n",
    "test_results =np.array(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy over epochs\n",
    "\n",
    "import matplotlib.pyplot as plt      #These provide matlab type of plotting functions\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline                   \n",
    "\n",
    "plt.figure()\n",
    "plt.axis([0 ,epochs, 0, 1])\n",
    "plt.plot(train_results[:,0]) #0th col is accuracy, col 1 is loss\n",
    "plt.plot(test_results[:,0])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some sample predictions\n",
    "with torch.no_grad():\n",
    "  for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output       = mymodel(data)\n",
    "        _, predicted = torch.max(output, dim=1)\n",
    "        break\n",
    "output=output.cpu().numpy()\n",
    "predicted=predicted.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To view a sample image and predictions\n",
    "import matplotlib.pyplot as plt      \n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#use 0 to 5, or 1 to 6, etc.. (but 5 at a time)\n",
    "range_start=11\n",
    "for i in range(range_start,range_start+5):\n",
    "  #print('For example i:',i,' rawoutput:',np.round(output[i,:],1))\n",
    "  print('For example i:',i,' predicted:',predicted[i])\n",
    "  print('----------------------------------------------------')\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    tmpimg=np.squeeze(data[range_start+i,:,:,:].cpu()).reshape((28,28))\n",
    "    plt.imshow(tmpimg,'gray')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ GET WEIGHTS From Convolution Layer and make mosaic image\n",
    "\n",
    "#take weights from conv layer and detach from model, move to cpu (in case we are on gpu)\n",
    "Wlist   =mymodel.conv1.weight.detach().cpu()  #returns array: numfilters,1,3,3 \n",
    "\n",
    "W3Dchan     =np.squeeze(Wlist) #get the channels \n",
    "print(\"W3D shape:\"+str(W3Dchan.shape))\n",
    "\n",
    "#plot mosaic of filters of \n",
    "ncol =4\n",
    "nrow =np.ceil(16/ncol).astype(int)   #assume 16 is number of filters\n",
    "plt.figure()\n",
    "for i in range(min(16,W3Dchan.shape[0])):\n",
    "   plt.subplot(nrow,ncol,i+1)\n",
    "   plt.imshow(W3Dchan[i],'gray')\n",
    "   plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "print('done plotting weights mosaic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ---------------- NOW Visualize the activations for the first training example --------\n",
    "#   1. gather activations from the model layers\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "with torch.no_grad():\n",
    "  for batch_idx, (data, target) in enumerate(test_loader):\n",
    "      break\n",
    "#try different images by change 0:1 to  1:2, etc..      \n",
    "test_img   = data[0:1,:,:,:].to(device)\n",
    "model_pred = mymodel(test_img) #run model on 1 imput\n",
    "conv1_act  = np.squeeze(activations['conv1'].detach().cpu())\n",
    "print('activation array shape:',conv1_act.shape)\n",
    "# 2.  Now output a mosaic of layer 1\n",
    "ncol =4\n",
    "nrow =np.ceil(16/ncol).astype(int)\n",
    "plt.figure()\n",
    "for i in range(min(conv1_act.shape[0],16)):  \n",
    "   plt.subplot(nrow,ncol,i+1)\n",
    "   plt.imshow(conv1_act[i,:,:],'gray')\n",
    "   plt.axis('off')\n",
    "#plt.savefig(\"test.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "print('done plotting layer1 activation output mosaic')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
